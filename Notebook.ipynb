{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from skimage.transform import resize\n",
    "\n",
    "import architecture.ShuffleNetV1.network as ShuffleNetV1\n",
    "import architecture.ShuffleNetV2.network as ShuffleNetV2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to weights\n",
    "paths = {}\n",
    "\n",
    "# shufflenet 1\n",
    "# group size 3\n",
    "paths['s1_g3_05'] = 'weights/ShuffleNetV1/Group3/models/0.5x.pth.tar'\n",
    "paths['s1_g3_10'] = 'weights/ShuffleNetV1/Group3/models/1.0x.pth.tar'\n",
    "paths['s1_g3_15'] = 'weights/ShuffleNetV1/Group3/models/1.5x.pth.tar'\n",
    "paths['s1_g3_20'] = 'weights/ShuffleNetV1/Group3/models/2.0x.pth.tar'\n",
    "\n",
    "# shufflenet 1\n",
    "# group size 8\n",
    "paths['s1_g8_05'] = 'weights/ShuffleNetV1/Group8/models/0.5x.pth.tar'\n",
    "paths['s1_g8_10'] = 'weights/ShuffleNetV1/Group8/models/1.0x.pth.tar'\n",
    "paths['s1_g8_15'] = 'weights/ShuffleNetV1/Group8/models/1.5x.pth.tar'\n",
    "paths['s1_g8_20'] = 'weights/ShuffleNetV1/Group8/models/2.0x.pth.tar'\n",
    "\n",
    "# shufflenet 2\n",
    "paths['s2_05'] = 'weights/ShuffleNetV2/models/0.5x.pth.tar'\n",
    "paths['s2_10'] = 'weights/ShuffleNetV2/models/1.0x.pth.tar'\n",
    "paths['s2_15'] = 'weights/ShuffleNetV2/models/1.5x.pth.tar'\n",
    "paths['s2_20'] = 'weights/ShuffleNetV2/models/2.0x.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible configurations\n",
    "configurations = [\n",
    "    's1_g3_05',\n",
    "    's1_g3_10',\n",
    "    's1_g3_15',\n",
    "    's1_g3_20',\n",
    "    's1_g8_05',\n",
    "    's1_g8_10',\n",
    "    's1_g8_15',\n",
    "    's1_g8_20',\n",
    "    's2_05',\n",
    "    's2_10',\n",
    "    's2_15',\n",
    "    's2_20'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads a model into the \"model\" variable\n",
    "# configuration is a string that specifies the model\n",
    "def load_model(configuration):\n",
    "\n",
    "    print('Loading model ' + configuration)\n",
    "\n",
    "    # split the configuration into its parameters\n",
    "    parameters = configuration.split('_')\n",
    "\n",
    "    # get the path to the weights\n",
    "    path = paths[configuration]\n",
    "\n",
    "    # load the weights\n",
    "    checkpoint = torch.load(path, map_location=torch.device('cpu'))\n",
    "\n",
    "    # all keys in checkpoint have an unnecessary 'module.' prefix, so we remove it\n",
    "    state_dict = {k.replace('module.', ''): v for k, v in checkpoint['state_dict'].items()}\n",
    "\n",
    "    # all keys have an unnecessary 'module.' prefix\n",
    "    # so we remove it\n",
    "    state_dict = {k.replace('module.', ''): v for k, v in checkpoint['state_dict'].items()}\n",
    "\n",
    "    # ShuffleNetV1\n",
    "    if parameters[0] == 's1':\n",
    "\n",
    "        model_name = 'ShuffleNetV1'\n",
    "        groups = int(parameters[1][1:])\n",
    "        size = parameters[2][0] + '.' + parameters[2][1:] + 'x'\n",
    "\n",
    "        model = ShuffleNetV1.ShuffleNetV1(model_size=size, group=groups)\n",
    "        \n",
    "    # ShuffleNetV2\n",
    "    elif parameters[0] == 's2':\n",
    "        \n",
    "        model_name = 'ShuffleNetV2'\n",
    "        groups = 2\n",
    "        size = parameters[1][0] + '.' + parameters[1][1:] + 'x'\n",
    "\n",
    "        model = ShuffleNetV2.ShuffleNetV2(model_size=size)\n",
    "\n",
    "    else:\n",
    "        # invalid configuration\n",
    "        raise Exception('Invalid configuration ' + configuration)\n",
    "\n",
    "    # load the weights into the architecture\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "\n",
    "    return_string = model_name + ' ' + size + ', ' + str(groups) + ' groups'\n",
    "\n",
    "    return return_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the class labels\n",
    "path_labels = 'imagenet-simple-labels.json'\n",
    "with open(path_labels) as f:\n",
    "    labels = json.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop a 224x224 region from the center of the image\n",
    "def center_crop(img):\n",
    "    \"\"\"Returns a center crop of an image\n",
    "    \n",
    "    Arguments:\n",
    "        numpy.ndarray -- input image\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray -- center cropped image\n",
    "    \"\"\"\n",
    "\n",
    "    # get the dimensions of the image\n",
    "    height, width, _ = img.shape\n",
    "\n",
    "    # calculate the top left corner\n",
    "    top = (height - 224) // 2\n",
    "    left = (width - 224) // 2\n",
    "\n",
    "    # calculate the bottom right corner\n",
    "    bottom = top + 224\n",
    "    right = left + 224\n",
    "\n",
    "    # crop the image\n",
    "    img = img[top:bottom, left:right, :]\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the class of an image and time it\n",
    "def timed_prediction(tensor):\n",
    "    \"\"\"Returns the predicted class of an image\n",
    "    \n",
    "    Arguments:\n",
    "        torch.Tensor -- input image\n",
    "\n",
    "    Returns:\n",
    "        str -- predicted class\n",
    "    \"\"\"\n",
    "\n",
    "    # start the timer\n",
    "    start = time.time()\n",
    "\n",
    "    # predict the class\n",
    "    with torch.no_grad():\n",
    "        output = model(tensor)\n",
    "\n",
    "    # end the timer\n",
    "    end = time.time()\n",
    "    elapsed_time = end-start\n",
    "\n",
    "    # get the top 3 labels\n",
    "    _, indices = torch.sort(output, descending=True)\n",
    "    indices = indices[0][:3]\n",
    "\n",
    "    label = [labels[int(idx.item())] for idx in indices]\n",
    "\n",
    "    return label, elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the class of an image\n",
    "# returns the top 3 classes and prediction time in seconds\n",
    "def predict(img):\n",
    "    \n",
    "    img = center_crop(img)\n",
    "    input_tensor = torch.from_numpy(img).unsqueeze(0).permute(0, 3, 1, 2).float()\n",
    "\n",
    "    # Get the prediction\n",
    "    prediction, time = timed_prediction(input_tensor)\n",
    "\n",
    "    text_prediction = prediction[0] + \", \" + prediction[1] + \", \" + prediction[2]\n",
    "    text_time = str(round(time, 5)) + \" s\"\n",
    "\n",
    "    return text_prediction, text_time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David Rath\\AppData\\Local\\Temp\\ipykernel_27664\\513845350.py:9: UserWarning: You have unused kwarg parameters in Dropdown, please remove them: {'default': 's2_10'}\n",
      "  dropdown = gr.Dropdown(dropdown_options, label=\"Choose a Model\", default=\"s2_10\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7927\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7927/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model s1_g3_15\n",
      "model size is  1.5x\n",
      "Loading model s1_g8_15\n",
      "model size is  1.5x\n",
      "Loading model s1_g3_05\n",
      "model size is  0.5x\n",
      "Loading model s1_g3_10\n",
      "model size is  1.0x\n",
      "Loading model s1_g3_15\n",
      "model size is  1.5x\n",
      "Loading model s1_g3_20\n",
      "model size is  2.0x\n",
      "Loading model s1_g8_05\n",
      "model size is  0.5x\n",
      "Loading model s1_g8_10\n",
      "model size is  1.0x\n",
      "Loading model s1_g8_15\n",
      "model size is  1.5x\n",
      "Loading model s1_g8_20\n",
      "model size is  2.0x\n",
      "Loading model s2_05\n",
      "model size is  0.5x\n",
      "Loading model s2_20\n",
      "model size is  2.0x\n",
      "Loading model s1_g3_15\n",
      "model size is  1.5x\n",
      "Loading model s1_g3_05\n",
      "model size is  0.5x\n",
      "Loading model s1_g3_10\n",
      "model size is  1.0x\n"
     ]
    }
   ],
   "source": [
    "custom_css = \"#row1 {height: 60vh !important;overflow-y: auto;}\"\n",
    "\n",
    "with gr.Blocks(css=custom_css) as demo:\n",
    "    gr.Markdown(\"# ShuffleNet Demo\")\n",
    "\n",
    "    with gr.Row(elem_id=\"row0\"):\n",
    "\n",
    "        with gr.Column(scale = 5):\n",
    "            dropdown = gr.Dropdown(configurations, label=\"Choose a Model\", default=\"s2_10\")\n",
    "\n",
    "        with gr.Column(scale = 2):\n",
    "            label_model = gr.Label(\"-\", label=\"Model\")\n",
    "        \n",
    "        dropdown.change(load_model, inputs=dropdown, outputs=label_model)\n",
    "\n",
    "        \n",
    "\n",
    "    with gr.Row(elem_id=\"row1\"):\n",
    "        with gr.Column(scale = 5):\n",
    "            input_image = gr.Image(shape=(224, 224))\n",
    "\n",
    "        with gr.Column(scale = 2):\n",
    "            label_prediction = gr.Label(\"-\", label=\"Prediction\")\n",
    "            label_time = gr.Label(\"-\", label=\"Prediction time\")\n",
    "\n",
    "    btn = gr.Button(\"Predict\")\n",
    "    btn.click(predict, inputs=input_image, outputs=[label_prediction, label_time])\n",
    "\n",
    "        \n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
